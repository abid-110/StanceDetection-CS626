{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependencies \n",
    "! pip install skipthoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\vinee\\anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model parameters...\n",
      "Compiling encoders...\n",
      "Loading tables...\n",
      "Packing up...\n"
     ]
    }
   ],
   "source": [
    "import skipthoughts\n",
    "model = skipthoughts.load_model()\n",
    "encoder = skipthoughts.Encoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_features(headline, body):\n",
    "\n",
    "  train_headline_sentences = []\n",
    "  train_body_sentences = []\n",
    "  train_headline_sentences.append(headline)\n",
    "  train_body_sentences.append(body)\n",
    "\n",
    "  ext = []\n",
    "  i = 0\n",
    "  for sent1,sent2 in zip(train_headline_sentences,train_body_sentences):\n",
    "    print(i)\n",
    "    i+=1\n",
    "    vec = []\n",
    "    #character ngrams\n",
    "    for n in range(2,17):\n",
    "      n_grams_1 = ngrams(sent1.lower(), n)\n",
    "      n_grams_2 = ngrams(sent2.lower(),n)\n",
    "      vec.append(len(list(set(n_grams_1).intersection(n_grams_2))))\n",
    "\n",
    "    #word ngrams\n",
    "    for n in range(2,7):\n",
    "      n_grams_1 = ngrams(sent1.lower().split(), n)\n",
    "      n_grams_2 = ngrams(sent2.lower().split(),n)\n",
    "      vec.append(len(list(set(n_grams_1).intersection(n_grams_2))))\n",
    "    vec.append(0)\n",
    "    return np.array(vec).reshape((1,21))\n",
    "#     #Sentence polarity\n",
    "#     flag=False\n",
    "#     text1 = Text(sent1)\n",
    "#     text2 = Text(sent2)\n",
    "#     pol1 = 0\n",
    "#     pol2 = 0\n",
    "#     for word in text1.words:\n",
    "#       try:\n",
    "#         pol1+=word.polarity\n",
    "#       except:\n",
    "#         flag=True\n",
    "#         vec.append(0)\n",
    "#         break\n",
    "#     if (flag==True):\n",
    "#       ext.append(vec)\n",
    "#       continue\n",
    "#     flag=False\n",
    "#     for word in text2.words:\n",
    "#       try:\n",
    "#         pol2+=word.polarity\n",
    "#       except:\n",
    "#         flag=True\n",
    "#         vec.append(0)\n",
    "#         break\n",
    "#     if (flag==True):\n",
    "#       ext.append(vec)\n",
    "#       continue\n",
    "    \n",
    "    \n",
    "#     pol1 = pol1/(len(sent1.split())*1.0)\n",
    "#     pol2 = pol2/(len(sent2.split())*1.0)\n",
    "#     print(\"pol1 : \", pol1)\n",
    "#     print(\"pol2 : \", pol2)\n",
    "#     print(pol1-pol2)\n",
    "#     vec.append(pol1-pol2)\n",
    "\n",
    "#     ext.append(vec)\n",
    "\n",
    "#   return np.array(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_features(h, b):\n",
    "    \n",
    "  dataset = pd.read_csv('D:\\\\FinalTrainSet.csv')\n",
    "  headline = dataset['Headline']\n",
    "  body = dataset['Body']\n",
    "\n",
    "  v1 = TfidfVectorizer()\n",
    "  statistical_h = v1.fit(headline)\n",
    "  arr = statistical_h.transform([h])\n",
    "  v2 = TfidfVectorizer(max_features=(10000-arr.shape[1]))\n",
    "  statistical_b = v2.fit(body)\n",
    "  brr = statistical_b.transform([b])\n",
    "#   #b.shape\n",
    "#   statistical_h = np.append(a, b).reshape((1, 2261))\n",
    "#   print(statistical_h.shape)\n",
    "#   print(statistical_b.shape)\n",
    "#   c = statistical_b.toarray()\n",
    "#   #c.shape[1]\n",
    "#   d = np.zeros((1, 10000 - 2261 - c.shape[1]))\n",
    "#   #d.shape\n",
    "#   statistical_b = np.append(c, d).reshape((1, 10000-2261))\n",
    "#   #print(statistical_b.shape)\n",
    "#   print(arr.shape)\n",
    "#   print(brr.shape)\n",
    "  final_statistical_features = np.concatenate((arr.toarray(), brr.toarray()),axis = 1)\n",
    "  print(final_statistical_features.shape)\n",
    "\n",
    "  return final_statistical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_features(h,b):\n",
    "    neural_head = encoder.encode([h])\n",
    "    neural_body = encoder.encode([b])\n",
    "    neural_head = neural_head[0,0:2400].reshape((1,2400))\n",
    "    neural_body =neural_body[0,0:2400].reshape((1,2400))\n",
    "#     print(neural_head.shape)\n",
    "#     print(neural_body.shape)\n",
    "    final_neural_features = np.concatenate((neural_head,neural_body),axis=1)\n",
    "#     print(final_neural_features.shape)\n",
    "    return final_neural_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('D:\\\\final.h5') # change the location of the model to './path/to/model/on/your/system'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_demo_sent = 'ISIL Beheads American Photojournalist in Iraq'\n",
    "body_demo_sent = 'James Foley, an American journalist who went missing in Syria more than a year ago, has reportedly been executed by the Islamic State, a militant group formerly known as ISIS.Video and photos purportedly of Foley emerged on Tuesday. A YouTube video -- entitled \"A Message to #America (from the #IslamicState)\" -- identified a man on his knees as \"James Wright Foley,\" and showed his execution.This is a developing story. Check back here for updates.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000)\n",
      "0\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "crr = statistical_features(head_demo_sent, body_demo_sent)\n",
    "drr = external_features(head_demo_sent, body_demo_sent)\n",
    "err = neural_features(head_demo_sent,body_demo_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x=[err,drr,crr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline and body pairs agree with each other\n"
     ]
    }
   ],
   "source": [
    "if(y_pred_[0] == 0):\n",
    "    print(\"Headline and body pairs agree with each other\")\n",
    "elif(y_pred_[0] == 1):\n",
    "    print(\"Headline and body pairs disagree with each other\")\n",
    "elif(y_pred_[0]==2):\n",
    "    print(\"Headline and body pairs are discussion statements\")\n",
    "elif(y_pred_[0]==3):\n",
    "    print(\"Headline and body pairs are unrelated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
